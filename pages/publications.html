<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>Publications â€” A Place for Asides </title>
	<meta name="description" content="">
	<meta name="author" content="Peter">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
	<!--[if lt IE 9]>
		<script src="../theme/html5.js"></script>
		<![endif]-->
	<link href="../theme/css/ipython.css" rel="stylesheet">
	<link href="../theme/css/jquery.tocify.css" rel="stylesheet">
	<link href="../theme/css/lightbox.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
	<!--
	<link href="https://stackpath.bootstrapcdn.com/bootswatch/4.3.1/minty/bootstrap.min.css" rel="stylesheet">
	-->
	<link href="../theme/css/local.css" rel="stylesheet">
	<link href="../theme/css/pygments.css" rel="stylesheet">
</head>
<body>
<div class="container main">
	<div class="page-header">
		<div class="row">
			<div class="col-8 col-sm-8">
			<h1><a href="../">A Place for Asides</a>
				<br>			</div>
			<div class="col-4 col-sm-4 page-header-links">
				<p><a href="/pages/about.html">About</a> | <a href="/pages/publications.html">Publications</a> | <a href="/pages/previous-projects.html">Previous Projects</a> | <a href="/blog/index.html">Blog</a> | <a href="/pages/books.html">Book List</a> </p>
			</div>
		</div>
	</div>
	<div class="row">
		<div class="col-md-8 col-md-offset-2">
        
<section id="content" class="body">    
    <div class="row">
<div class="col-7 col-sm-7">
<h1 style="text-align:center">Peter Mortimer</h1>
<p><br/><br/></p>
<p style="margin: 0px;">I'm a PhD candidate at the Bundeswehr University in Munich. I'm interested in Machine Learning, Computer Vision, and Data Visualization.</p>
<p><br/></p>
<p style="margin: 0px; text-align: center;"><a href="mailto:peter.mortimer@unibw.de">Email</a> &middot; <a href="https://github.com/tonyromarock">GitHub</a> &middot; <a href="https://scholar.google.com/citations?user=ckEIQp0AAAAJ">Google Scholar</a> &middot; <a href="https://arxiv.org/search/cs?query=Mortimer%2C+Peter&searchtype=author&abstracts=show&order=-announced_date_first">arXiv</a></p>
</div>
<div class="col-5 col-sm-5">
<a href="/images/about/peter_kyoto.jpg"><img style="width:100%;max-width:100%;border-radius: 50%;" src="/images/about/peter_kyoto.jpg"/></a>
</div>
</div>

<h1>Research</h1>
<p>Here are all my publcations listed with links to the papers and repositories.</p>
<hr>

<div class="row">
<div class="col-2 col-sm-2">
<a href="/images/publications/icra2024/goose-title-card.jpg" 
data-lightbox="uoa-lightbox" 
data-title="We present the German Outdoor and Offroad Dataset (GOOSE), a comprehensive dataset specifically designed for unstructured outdoor environments. The GOOSE dataset incorporates 10 000 labeled pairs of images and point clouds, which are utilized to train a range of state-of-the-art segmentation models on both image and point cloud data. We open source the dataset, along with an ontology for unstructured terrain, as well as dataset standards and guidelines." 
data-alt=""><img src="/images/publications/icra2024/goose-title-card.jpg"/></a>
</div>
<div class="col-10 col-sm-10">
<p style="margin: 0px;"><b>Peter Mortimer</b>, Raphael Hagmanns, Miguel Granero, Thorsten Luettel, Janko Petereit and Hans-Joachim Wuensche</p> 
<p style="margin: 0px;">"The GOOSE Dataset for Perception in Unstructured Environments"</p>
<p style="margin: 0px;"><i>International Conference on Robotics and Automation (<b>ICRA</b>)</i>, Yokohama, Japan, May 2024.</p>
<p><a href="https://goose-dataset.de/">Project Page</a> &middot; <a href="https://goose-dataset.de/">Paper</a> &middot; <a href="bibtex/icra2024.bib">Bibtex</a>
</div>
</div>

<hr>

<div class="row">
<div class="col-2 col-sm-2">
<a href="/images/publications/iclr2023/Dpt_MonoDepth_Position_and_Scale.png" 
data-lightbox="uoa-lightbox" 
data-title="In this blog post, we investigate the performance of the vision transformer DPT for monocular depth estimation from single images. Here we compare an object's detected depth for DPT and the fully-convolutional MonoDepth when only changing the apparent size or the vertical position of an object." 
data-alt=""><img src="/images/publications/iclr2023/Dpt_MonoDepth_Position_and_Scale.png" /></a>
</div>
<div class="col-10 col-sm-10">
<p style="margin: 0px;"><b>Peter Mortimer</b> and Hans-Joachim Wuensche</p> 
<p style="margin: 0px;">"How Do Vision Transformers See Depth in Single Images?"</p>
<p style="margin: 0px;"><i>Workshop on Scene Representations for Autonomous Driving (<b>SR4AD @ ICLR</b>)</i>, Kigali, Ruwanda, May 2023.</p>
<p><a href="https://sr4ad-vit-mde.github.io/blog/2023/visual-cues-monocular-depth-estimation/">Blog Post</a> &middot; <a href="https://sr4ad-vit-mde.github.io/web-slides/sr4ad/presentation.html">Presentation Slides</a> &middot; <a href="https://youtu.be/0ccu72jOh_k?si=jqaIerl58flkffah&t=2540">Videos</a> &middot; <a href="bibtex/sr4ad-iclr2023.bib">Bibtex</a>
</div>
</div>

<hr>

<div class="row">
<div class="col-2 col-sm-2">
<a href="/images/publications/iros2022/title-card.png" 
data-lightbox="uoa-lightbox" 
data-title="TAS-NIR is a novel dataset consisting of 209 semantically segmented and aligned VIS+NIR images in different driving scenarios in unstructured outdoor environments. The fine-grained semantic segmentation of the different vegetation and ground surface types allows closer analysis of VIS+NIR based features. The visible light color image (VIS) and near infrared image (NIR) can be combined to generate vegetation indices like the NDVI image (bottom)." 
data-alt=""><img src="/images/publications/iros2022/title-card.png" /></a>
</div>
<div class="col-10 col-sm-10">
<p style="margin: 0px;"><b>Peter Mortimer</b> and Hans-Joachim Wuensche</p> 
<p style="margin: 0px;">"TAS-NIR: A VIS+NIR Dataset for Fine-grained Semantic Segmentation in Unstructured Outdoor Environments"</p>
<p style="margin: 0px;"><i>Workshop on Planning, Perception and Navigation for Intelligent Vehicles (<b>PPNIV @ IROS</b>)</i>, Kyoto, Japan, October 2022.</p>
<p><a href="https://mucar3.de/iros2022-ppniv-tas-nir">Project Page</a> &middot; <a href="https://project.inria.fr/ppniv22/files/2022/10/PPNIV_TAS-NIR_Paper.pdf">Paper</a> &middot; <a href="https://drive.google.com/uc?export=download&id=1nSyiQDfSvWPMjx4-6Mz01qSda_kPYpsG">Dataset</a> &middot; <a href="bibtex/ppniv-iros2022.bib">Bibtex</a>
</div>
</div>

<hr>

<div class="row">
<div class="col-2 col-sm-2">
<a href="/images/publications/icpr2020/image_cube.png" 
data-lightbox="uoa-lightbox" 
data-title="TAS500 is a novel semantic segmentation dataset for autonomous driving in unstructured environments. TAS500 offers fine-grained vegetation and terrain classes to learn drivable surfaces and natural obstacles in outdoor scenes effectively." 
data-alt=""><img src="/images/publications/icpr2020/image_cube.png" /></a>
</div>
<div class="col-10 col-sm-10">
<p style="margin: 0px;">Kai Andreas Metzger, <b>Peter Mortimer</b> and Hans-Joachim Wuensche</p> 
<p style="margin: 0px;">"A Fine-Grained Dataset and its Efficient Semantic Segmentation for Unstructured Driving Scenarios"</p>
<p style="margin: 0px;"><i>International Conference on Pattern Recognition (<b>ICPR</b>)</i>, Milan, Italy, January 2021.</p>
<p><a href="https://mucar3.de/icpr2020-tas500/">Project Page</a> &middot; <a href="https://drive.google.com/file/d/1TeJK-3EBkXzD9FCq4LOLGFRD3lmKqVdp/view">Paper</a> &middot; <a href="https://rzunibw-my.sharepoint.com/:f:/g/personal/thorsten_luettel_rzunibw_onmicrosoft_com/Evdia5SSRaRPuSO2CNsNHY8B3xdK8eHpG-9DSaeEbIJyUw?e=M6NMqI">Dataset</a> &middot; <a href="bibtex/icpr2020.bib">Bibtex</a>  <!--&middot; <a href="/">GitHub</a> --> 
</div>
</div>

<hr>

<h1>Talks</h1>
<p>Here are all my talks that are publicly available.</p>
<hr>

<div class="row">
<div class="col-10 col-sm-10">
<p style="margin: 0px;">"20/20 Robot Vision - How to setup cameras in ROS 1 & ROS 2 using camera_aravis"</p>
<p style="margin: 0px;">ROSCon 2022, Kyoto, Japan.</p>
<p><a href="https://vimeo.com/showcase/9954564/video/767140329">Video</a> &middot; <a href="/images/publications/roscon2022/ROSCon2022_PeterMortimer_20-20_Robot_Vision.pdf">Slides</a> &middot; <a href="https://github.com/FraunhoferIOSB/camera_aravis">GitHub</a> 
</div>
<div class="col-2 col-sm-2">
<a href="/images/publications/roscon2022/title-card.png" 
data-lightbox="uoa-lightbox" 
data-title="Industrial camera drivers like aravis give you control over many components of the image acquisiton process. Here you can observe the difference between minizing the gain (top) and minimizing the exposure time (bottom) on the amount of noise in the image." 
data-alt=""><img src="/images/publications/roscon2022/title-card.png"/></a>
</div>
</div>
</section>
		</div>
	</div> 	<!-- <hr> -->
</div> <!-- /container -->
<footer class="aw-footer bg-danger">
	<div class="container"> <!-- footer -->
		<div class="row">
			<div class="col-md-10 col-md-offset-1">
				<div class="row">
					<div class="col-md-3">
						<h4>Navigation</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="..">A Place for Asides</a></li>
							<li><a href="../pages/about.html"><i class="fa fa-About "></i> About</a></li>
							<li><a href="../pages/blogroll.html"><i class="fa fa-Blogroll "></i> Blogroll</a></li>
							<li><a href="../pages/books.html"><i class="fa fa-Books I've Read "></i> Books I've Read</a></li>
							<li><a href="../pages/previous-projects.html"><i class="fa fa-Previous Projects "></i> Previous Projects</a></li>
							<li><a href="../pages/publications.html"><i class="fa fa-Publications "></i> Publications</a></li>
							<li><a href="https://tonyromarock.github.io/feeds/all.atom.xml" type="application/atom+xml"><i class="fa fa-rss "></i> atom</a></li>
						</ul>
					</div>
					<div class="col-md-3">
						<h4>Author</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="https://github.com/tonyromarock">GitHub</a></li>
						</ul>
					</div>
					<div class="col-md-3">
						<h4>Categories</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="../category/linux.html">Linux (1)</a></li>
							<li><a href="../category/nonfiction.html">Nonfiction (1)</a></li>
							<li><a href="../category/python.html">Python (3)</a></li>
						</ul>
					</div>
				</div>
			</div>
		</div>
	</div>
</footer>
<div class="container bottom">
	<div class="row">
		<div class="col-md-12 text-center center-block aw-bottom">
			<p>&copy; Peter 2020</p>
			<p>Powered by Pelican</p>
		</div>
	</div>
</div>
<!-- JavaScript -->
<script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
<script src="../theme/js/jquery-ui-1.9.1.custom.min.js"></script>
<script src="../theme/js/jquery.tocify.min.js"></script>
<script src="../theme/js/lightbox.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script type="text/javascript">
jQuery(document).ready(function($) {
	$("div.collapseheader").click(function () {
		$header = $(this).children("span").first();
		$codearea = $(this).children(".input_area");
		$codearea.slideToggle(500, function () {
			$header.text(function () {
				return $codearea.is(":visible") ? "Collapse Code" : "Expand Code";
			});
		});
	});
});
$(function() { 
	var toc = $("#toc").tocify({
		context:"div.article-body", 
		selectors:"h1,h3",
		showAndHide:"false",
		extendPage:"false",
		history:"true",
		scrollHistory:"true"
	}).data("toc-tocify"); 

});
lightbox.option({
	'wrapAround': true
});
</script>
</body>
</html>