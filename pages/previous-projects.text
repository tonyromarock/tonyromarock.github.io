Title: Previous Projects
Date: 2019-07-10 23:55
Category: Author
Tags: Data Science, Computer Vision
Slug: previous-projects
Authors: Peter Mortimer
Summary: An overview of previous projects I have worked on.

# Previous Projects

Here is a brief overview of different projects I have been working on over the course of my studies and internships. For many of the projects, the source code is not publicly available. Please visit my [GitHub profile](https://github.com/tonyromarock) if you are interested in the code I have written.

<hr>

**Automated Extraction of Road Features Using LiDAR Data**
<div class="row">
<div class="col-8 col-sm-8">
<p>This research internship was organized by the University of Alberta Research Experience (UARE) program. At the City of Edmonton Research Chair in Urban Traffic Safety I developed prototypes for automatically detecting structural properties from LiDAR scans of highways in Alberta. Among these structural properties were measuring the lane width of the road and detecting pavement distresses indicating fatigue at the given highway segment.</p>
<p><b>Technologies:</b> MATLAB, CloudCompare</p>
<p>May 2019 - August 2019</p>
</div>
<div class="col-4 col-sm-4">
<a href="/images/prev_projects/uare_pavement.png" 
data-lightbox="uoa-lightbox" 
data-title="A local thresholding on elevation gradients and intensity values allowed for the detection of longitudinal cracks and transverse cracks in high-resolution LiDAR point clouds." 
data-alt="An image of a LiDAR road segment with visible cracks both along the road (so-called longitudinal cracks) and perpendicular to the road (so-called transverse cracks). For both type of cracks there is also an example image from the real world. The LiDAR recoding was made with the Tetra Tech PSP-7000 survey vehicle."><img src="/images/prev_projects/uare_pavement.png"></a>
</div>
</div>
<hr>

**3D Instances from a single RGB Image**
<div class="row">
<div class="col-8 col-sm-8">
<p>In my master thesis I worked on using deep learning to detect the placement of 3D objects within a scene from a single RGB image of the indoor scene. I compared the predictive performance of using a point cloud object representation to a factored 3D object representation as output of the network architecture.</p>
<p><b>Technologies:</b> PyTorch</p>
<p>September 2018 - May 2019</p>
</div>
<div class="col-4 col-sm-4">
<a href="/images/prev_projects/ma_bedroom_prediction.png" 
data-lightbox="master-thesis-lightbox" 
data-title="The Factored3D network uses a factored object representation to predict the 3D position of objects in a scene. In the factored object representation the voxelized shape, position, scale, and rotation are predicted separately. I experimented with using different point cloud loss functions to fine-tune the overall predicition performance in a holistic manner." 
data-alt=""><img src="/images/prev_projects/ma_bedroom_prediction.png"></a>

<a href="/images/prev_projects/ma_scene_predictions.png" 
data-lightbox="master-thesis-lightbox" 
style="display:none"
data-title="Here are a few example predictions of Factored3D on synthetic indoor scenes from the SUNCG dataset. The first column shows the input image given to the network. The second column shows the ground truth voxelized shape and position of each object in the scene. The third column shows the predicted scene of Factored3D trained using the suggested training stages by the original authors Tulsiani et al. The fourth column shows the predicted scene using the additional Earth Mover's distance on the point cloud representation of the objects to improve the overall prediction performance in a holistic manner." 
data-alt="Here are a few example predictions of Factored3D on synthetic indoor scenes from the SUNCG dataset. The first column shows the input image given to the network. The second column shows the ground truth voxelized shape and position of each object in the scene. The third column shows the predicted scene of Factored3D trained using the suggested training stages by the original authors Tulsiani et al. The fourth column shows the predicted scene using the additional Earth Mover's distance on the point cloud representation of the objects to improve the overall prediction performance in a holistic manner."><img src="/images/prev_projects/ma_scene_predictions.png" style="visibilitydisplay:none;"></a>

<a href="/images/prev_projects/ma_nyuv2_predictions.png" 
data-lightbox="master-thesis-lightbox" 
style="display:none"
data-title="Here are a few example predictions of Factored3D on real world indoor scenes from the NYU-Depth V2 dataset. The first column shows the input image and the predicted object bounding boxes of the original Factored3D implementation by Tulsiani et al. The second column shows the predicted objects in the scene of the original Factored3D implementation. The third column shows the input image and the predicted object bounding boxes produced by my implementation of Factored3D. The fourth column shows the predicted objects in the scene of my implementation of Factored3D, which uses the Earth Mover's distance as a loss function on the point cloud representation of the scene to improve the overall performance in a holistic manner." 
data-alt="Here are a few example predictions of Factored3D on real world indoor scenes from the NYU-Depth V2 dataset. The first column shows the input image and the predicted object bounding boxes of the original Factored3D implementation by Tulsiani et al. The second column shows the predicted objects in the scene of the original Factored3D implementation. The third column shows the input image and the predicted object bounding boxes produced by my implementation of Factored3D. The fourth column shows the predicted objects in the scene of my implementation of Factored3D, which uses the Earth Mover's distance as a loss function on the point cloud representation of the scene to improve the overall performance in a holistic manner."><img src="/images/prev_projects/ma_nyuv2_predictions.png" style="display:none;"></a>

</div>
</div>
<hr>

**Development of a Car Detector**
<div class="row">
<div class="col-8 col-sm-8">
<p>In the course “Introduction to Image Analysis and Machine Learning” at the IT University of Copenhagen we developed a car detector as a final project. The car detector could detect cars driving along a highway. We used traditional image analysis techniques to detect image patches that potentially contain cars. We then used a convolutional neural network to classify the image patch.</p>
<p><b>Technologies:</b> Python, OpenCV</p>
<p>February 2018 - July 2018</p>
</div>
<div class="col-4 col-sm-4">
<a href="/images/prev_projects/highway_detector.png" 
data-lightbox="itu-cv-lightbox"
data-title="During my exchange at the IT University of Copenhagen I worked on creating a car detector as part of the introduction to Computer Vision and Image Analysis course. For the car detector I used a shallow CNN, which took potential preselected image patches as input. The preselected image patches were determined by using a traditional background subtraction from an empty image of the highway." 
data-alt="">
<img src="/images/prev_projects/highway_detector.png"></a>
</div>
</div>
<hr>

**Summer Internship at Spirent Communications as a Data Scientist**
<div class="row">
<div class="col-8 col-sm-8">
<p>During a 10 week summer internship I worked on two data science projects using the call detail record data of a large mobile network carrier in North America. The projects revolved around relating customer experience metrics to their overall mobile usage and detecting long-distance travellers based on their mobile usage.</p>
<p><b>Technologies:</b> Python, SQL</p>
<p>August 2017 - November 2017</p>
</div>
<div class="col-4 col-sm-4">
<a href="/images/prev_projects/cell_towers_mexico.png" 
data-lightbox="spirent-intern-lightbox"
data-title="This graph marks the locations of all cell towers in Mexico and compares this to all cell towers within a 10km radius to a commercial airport in Mexico. For the prototype I was developing, we were focusing on air travel and reducing the query size by limiting the search space of possible cell towers made the analysis feasible. You can tell from the left graph, that cell towers are placed along main roads and around highly populated areas." 
data-alt="This graph marks the locations of all cell towers in Mexico and compares this to all cell towers within a 10km radius to a commercial airport in Mexico. For the prototype I was developing, we were focusing on air travel and reducing the query size by limiting the search space of possible cell towers made the analysis feasible. You can tell from the left graph, that cell towers are placed along main roads and around highly populated areas.">
<img src="/images/prev_projects/cell_towers_mexico.png"></a>
</div>
</div>
<hr>

**Recognition of Structural Motifs**
<div class="row">
<div class="col-8 col-sm-8">
<p>In the practical course “Hands-On Deep Learning for Computer Vision and Biomedicine” we developed a fully convolutional network to detect realistic looking motifs in protein images of artificially constructed proteins. The motifs are represented as local features in the protein image, while the network output measured how realistic a particular motif looks compared to motifs found in known proteins</p>
<p><b>Technologies:</b> Python, Theano, Lasagne</p>
<p>April 2017 - August 2017</p>
</div>
<div class="col-4 col-sm-4">
<img src="/images/prev_projects/motif_image.png">
</div>
</div>
<hr>

**Visual Comparison of Isosurface Ensembles using Cutaway Views**
<div class="row">
<div class="col-8 col-sm-8">
<p>In my bachelor thesis at the chair for Computer Graphics and Visualization I implemented novel visualization techniques to analyze ensemble data, particularly for the domain of weather data. The use of cutting geometries to create cutaway views allows one to reduce the visual clutter in the ensemble data without losing the overall visual context. I developed a demo and use case that allowed the placement of cutting geometries to create cutaway views.</p>
<p><b>Technologies:</b> C++, Python, OpenGL</p>
<p>April 2016 - August 2016</p>
</div>
<div class="col-4 col-sm-4">
<img src="/images/prev_projects/BA_image.png">
</div>
</div>
