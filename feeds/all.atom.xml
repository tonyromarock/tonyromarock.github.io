<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>A Place for Asides</title><link href="http://tonyromarock.github.io/" rel="alternate"></link><link href="http://tonyromarock.github.io/feeds/all.atom.xml" rel="self"></link><id>http://tonyromarock.github.io/</id><updated>2020-04-12T23:00:00+02:00</updated><entry><title>Saving His Life by Lee Sandlin</title><link href="http://tonyromarock.github.io/saving-his-life.html" rel="alternate"></link><published>2020-04-12T23:00:00+02:00</published><updated>2020-04-12T23:00:00+02:00</updated><author><name>Peter Mortimer</name></author><id>tag:tonyromarock.github.io,2020-04-12:/saving-his-life.html</id><summary type="html">&lt;p&gt;Rereading the story of Lee Sandlin's father-in-law.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have become aware of Lee Sandlin when reading his essay &lt;a href="http://leesandlin.com/articles/LosingTheWar.htm"&gt;Losing The War&lt;/a&gt;, which was featured in Ira Glass' anthology &lt;em&gt;The New Kings of Nonfiction&lt;/em&gt;. This led me looking for more articles by Lee Sandlin. Many of his popular articles are freely available on his personal page and that is where I found his essay &lt;a href="http://www.leesandlin.com/articles/SavingHisLife.htm"&gt;Saving His Life&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In &lt;em&gt;Saving His Life&lt;/em&gt; Lee Sandlin chronicles the life of his father-in-law Nick Cherniavsky. The story of how Nick ended up in the US is very interesting. Nick lived in different Russian communities in Asia and eventually arrived the USA as a refugee. &lt;/p&gt;
&lt;p&gt;His memoirs show the interesting history many cities in Asia share being a meeting point for many ehnic groups. These melting pots often caused by the large refugee movements due to the many wars for territory in the first half of the 20th century and the expansive colonialism by the global powers starting already in earlier centuries.&lt;/p&gt;
&lt;p&gt;It is also a story about a time where, from our perpsective, these seemingly large and well-remembered events happened, but for people back then these news are often learned about in very unusual ways. It is interesting to see how these global events are interwoven into Nick's life in many different ways. &lt;/p&gt;
&lt;p&gt;I have also converted the story to the .epub format, so that someone interested in reading &lt;em&gt;Saving His Life&lt;/em&gt; can comfortably read it on their eBook reader:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://tonyromarock.github.io/extra/ebooks/Saving_His_Life.epub"&gt;Download Lee Sandlin's &lt;em&gt;Saving His Life&lt;/em&gt; for your eBook reader&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I hope you enjoy this article as much as I did. &lt;/p&gt;</content><category term="nonfiction"></category><category term="essays"></category></entry><entry><title>Using the Infrared Camera of the Dell XPS on Ubuntu 18.04</title><link href="http://tonyromarock.github.io/dell-xps-ir-camera.html" rel="alternate"></link><published>2019-11-05T17:55:00+01:00</published><updated>2019-11-05T17:55:00+01:00</updated><author><name>Peter Mortimer</name></author><id>tag:tonyromarock.github.io,2019-11-05:/dell-xps-ir-camera.html</id><summary type="html">&lt;p&gt;Accessing the infrared camera of the Dell XPS 13 9370.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was interested in using the unusual webcam setup of my Dell XPS 13 9370 notebook for some personal projects. The Dell XPS 13 9370 does not only have a regular color camera but also an infrared camera. On Windows the infrared camera and the color camera are used for Windows Hello, which allows the user to secure his PC using facial authentication (&lt;a href="https://github.com/boltgolt/howdy"&gt;Howdy&lt;/a&gt; is the closest equivalent for Linux). But when I tried to access my infrared camera using tools like &lt;code&gt;fswebcam&lt;/code&gt; or installing Howdy I ran into several issues.&lt;/p&gt;
&lt;p&gt;It turns out that the infrared camera of the Dell XPS 13 9370 uses an unusual 8-bit infrared video format called L8_IR (&lt;a href="https://github.com/boltgolt/howdy/issues/88#issuecomment-457708769"&gt;see this GitHub Issue for Howdy&lt;/a&gt;). This format is currently not supported by the driver in Ubuntu 18.04, but it was added to the linux kernel 4.19 (&lt;a href="https://github.com/torvalds/linux/commit/557a5c7fe6503230f6a3a41441981aed6e897d17"&gt;see the commit here&lt;/a&gt;) and that kernel version is expected to then be available on Ubuntu 19.04. That's good to know, but I still wanted to find a way to make use of the infrared camera on Ubuntu 18.04. &lt;/p&gt;
&lt;p&gt;Following an approach similar to &lt;a href="https://stackoverflow.com/questions/25799264/characterizing-my-raw-camera-output"&gt;NSchrading on Stack Overflow&lt;/a&gt; I tried to make sense of the raw data produced by the infrared camera using the following &lt;code&gt;fswebcam&lt;/code&gt; command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libv4l/v4l1compat.so fswebcam --palette GREY --device RAW:/dev/video1 --no-banner --no-timestamp --resolution &amp;quot;340x340&amp;quot; --dumpframe ir.raw
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The command contains many optional arguments, so I will briefly break down what the individual arguments do: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;LD_PRELOAD&lt;/code&gt; provides the absolute path to the Video4Linux library on my system, which has to be &lt;a href="https://stackoverflow.com/questions/426230/what-is-the-ld-preload-trick"&gt;preloaded&lt;/a&gt; for &lt;code&gt;fswebcam&lt;/code&gt; to correctly read from the raw video source of the infrared camera. You might have to change this path if Video4Linux is stored somewhere else on your system (&lt;a href="https://www.raspberrypi.org/forums/viewtopic.php?t=86265#post_content859415"&gt;see this comment on how to find the v4l1compat.so&lt;/a&gt;). &lt;/li&gt;
&lt;li&gt;&lt;code&gt;--palette GREY&lt;/code&gt; is the closest palette format supported by &lt;code&gt;fswebcam&lt;/code&gt; to L8_IR. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;--device RAW:/dev/video1&lt;/code&gt; specifies that we are reading the raw video data provided by the infrared camera, the color camera is found at &lt;code&gt;/dev/video0&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;--no-banner --no-timestamp&lt;/code&gt; remove the default banner added by &lt;code&gt;fswebcam&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;--resolution "340x340"&lt;/code&gt; defines the image resolution of the infrared camera, which is specified &lt;a href="https://topics-cdn.dell.com/pdf/xps-13-9370-laptop_setup-guide_en-us.pdf"&gt;here&lt;/a&gt; by Dell. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;--dumpframe&lt;/code&gt; specifies that we want to dump the raw frame to a file.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So running this command gives us an &lt;code&gt;ir.raw&lt;/code&gt; file. You can also notice that the infrared emitters light up red when taking an infrared image.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Both infrared emitters light up red when taking an image with the infrared camera." src="http://tonyromarock.github.io/images/ir_camera/ir_camera_crop.gif"&gt;&lt;/p&gt;
&lt;p&gt;Most programs cannot view .raw files, for this I wrote a quick script to validate if we are actually downloading a valid 8-bit infrared image. This &lt;a href="https://lwn.net/Articles/218798/"&gt;blog post&lt;/a&gt; by a Linux driver developer for camera devices explains very well how the different color formats for Video4Linux2 are defined using the &lt;a href="https://www.fourcc.org/fourcc.php"&gt;fourcc&lt;/a&gt; coding mechanism. The fornat for our 8-bit infrared format is &lt;code&gt;V4L_PIX_FMT_GREY&lt;/code&gt;. So one byte describes the grayscale value for the given pixel. With this knowledge and knowing the output resolution of the infrared camera, we can write the following script to display the infrared image using matplotlib:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;

&lt;span class="n"&gt;grays&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;340&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;340&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="kp"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ir.raw&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r+b&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;340&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;340&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;pixel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_bytes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;byteorder&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;big&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;grays&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pixel&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;grays&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here is an example image produced by my infrared camera:&lt;/p&gt;
&lt;p&gt;&lt;img alt="An example image produced by the infrared camera." src="http://tonyromarock.github.io/images/ir_camera/ir_face.png"&gt;&lt;/p&gt;
&lt;p&gt;So it took quite a bit to get to this point, but now we have the tools to implement some interesting Computer Vision applications using the stereo image setup of the Dell XPS 13 9370. I hope this is useful for other Dell users trying to get started with the built-in infrared camera.&lt;/p&gt;</content><category term="fswebcam"></category><category term="image processing"></category></entry><entry><title>Using binvox-rw-py with Python 3</title><link href="http://tonyromarock.github.io/binvox-rw-py3.html" rel="alternate"></link><published>2018-10-30T23:00:00+01:00</published><updated>2018-10-30T23:00:00+01:00</updated><author><name>Peter Mortimer</name></author><id>tag:tonyromarock.github.io,2018-10-30:/binvox-rw-py3.html</id><summary type="html">&lt;p&gt;My notes to using binvox-rw-py with Python 3.&lt;/p&gt;</summary><content type="html">&lt;p&gt;The Python project &lt;strong&gt;binvox-rw-py&lt;/strong&gt; is based on the &lt;a href="https://www.patrickmin.com/binvox/"&gt;binvox&lt;/a&gt; project from Patrick Min. It is a simple and easy-to-use tool to convert 3D model files into 3D voxel grids (it supports most of the common 3D model file formats: .obj, .ply, .stl; the output format is typically the custom &lt;strong&gt;.binvox&lt;/strong&gt; file format).&lt;/p&gt;
&lt;p&gt;Some research projects in the field of 3D machine learning may use this library to create voxelized scenes for training. These voxelized scenes are used to train networks to learn a rudimentary understanding of the scene's geometry in a more easily quantifiable way. This is how I stumbled upon the &lt;a href="https://github.com/dimatura/binvox-rw-py"&gt;binvox-rw-py&lt;/a&gt; module, which enables you to read .binvox files as 3-dimensional Numpy arrays in Python. You can also write numpy arrays into .binvox using binvox-rw-py.&lt;/p&gt;
&lt;h3&gt;troubles with writing .binvox files in Python 3&lt;/h3&gt;
&lt;p&gt;The original binvox-rw-py from the GitHub user &lt;a href="https://github.com/dimatura/"&gt;dimatura&lt;/a&gt; has issues with writing .binvox files when running it in Python 3, since it was implemented with the byte handling of Python 2 in mind. I discovered this after a few frustrating hours by simply reading and writing the same .binvox file I generated for my project and comparing the resulting voxelized scenes using &lt;a href="https://www.patrickmin.com/viewvox/"&gt;viewvox&lt;/a&gt; (which is also from Patrick Min):&lt;/p&gt;
&lt;p&gt;&lt;img alt="Comparing the resulting voxelized scenes when reading and writing the same .binvox file using binvox-rw-py with Python 3. The left image shows the broken scene voxelization using dimatura's module with Python 3, while the right image shows the correct scene voxelization using pclausen's module with Python 3." src="http://tonyromarock.github.io/images/binvox/binvox_write_compare.png"&gt;&lt;/p&gt;
&lt;p&gt;Luckly, the GitHub user &lt;a href="https://github.com/pclausen/"&gt;pclausen&lt;/a&gt; has already created a forked version of the &lt;a href="https://github.com/pclausen/binvox-rw-py"&gt;binvox-rw-py&lt;/a&gt; module that resolves this issue. This makes it possible to also use binvox-rw-py with Python 3.&lt;/p&gt;
&lt;p&gt;Unfortunately, the fixed binvox-rw-py module by pclausen does not seem as well known as the original module by dimatura if you compare the number of stars for each GitHub repository (at the time of writing dimatura's repository has 69 stars, while pclausen's repo only has 2 stars). pclausen has even originally created an &lt;a href="https://github.com/dimatura/binvox-rw-py/issues/3"&gt;issue&lt;/a&gt; in dimatura's issue tracker for the binvox-rw-py regarding the Python 3 writing issue. The issue has not been closed even until today.&lt;/p&gt;
&lt;p&gt;So I hope this post could help someone, who has been having issues using binvox-rw-py with Python 3 and save the person some time when trying to find the bug in his code.&lt;/p&gt;
&lt;p&gt;To install pclausen's binvox-rw-py module using pip, simply write the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install git+https://github.com/pclausen/binvox-rw-py
&lt;/pre&gt;&lt;/div&gt;</content><category term="binvox"></category><category term="pip"></category></entry><entry><title>Installing pip for Python in Blender</title><link href="http://tonyromarock.github.io/pip-blender-python.html" rel="alternate"></link><published>2018-09-30T18:05:00+02:00</published><updated>2018-09-30T18:05:00+02:00</updated><author><name>Peter Mortimer</name></author><id>tag:tonyromarock.github.io,2018-09-30:/pip-blender-python.html</id><summary type="html">&lt;p&gt;A short guide on how to install pip for the Python version bundled with Blender.&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you are working on a Computer Vision project in Python that requires 3D scene renderings, then &lt;a href="https://www.blender.org/"&gt;Blender&lt;/a&gt; is the way to go. Blender comes bundled with its own Python version, which can be used to write Python scripts for Blender. This is useful for automating rendering jobs, since Python in Blender provides you the &lt;strong&gt;bpy&lt;/strong&gt; module, which gives you access to Blender data, classes, and functions. &lt;/p&gt;
&lt;p&gt;Unfortunately, the Python in Blender does not share libraries with your system's Python. But if you don't want to be limited to the Python Standard Library available for Python in Blender, then you can install pip for Python in Blender.&lt;/p&gt;
&lt;p&gt;The blender Python binaries are here in the blender directory:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/your-blender-path/2.xx/python/bin/python.exe
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Use this python binary to run the &lt;a href="https://bootstrap.pypa.io/get-pip.py"&gt;get-pip.py&lt;/a&gt; script from the &lt;a href="https://pip.pypa.io/en/stable/installing/"&gt;pip documentation&lt;/a&gt; to install pip for Python in Blender. Don't forget to point explicitly to the python binary from your blender version. The installation command will look something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/your-blender-path/2.xx/python/bin/python.exe /Downloads/get-pip.py
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I ran the installation on Windows, which required me to open a Terminal with admin priviliges to execute the &lt;strong&gt;pip.exe&lt;/strong&gt;. Use this version of pip from Python in Blender (not the pip from your system's Python) to install 3rd party modules for Blender in Python: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/your-blender-path/2.xx/python.exe pip install module
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This should allow you to install 3rd party modules for your scripts in Python in Blender.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;Read these StackExchange questions for more information on installing pip for Python in Blender. My post is based on their answers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blender.stackexchange.com/questions/5596/advantages-of-using-python-in-blender-for-animation"&gt;Advantages of using Python in Blender for Animation?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blender.stackexchange.com/questions/1365/how-can-i-run-blender-from-command-line-or-a-python-script-without-opening-a-gui"&gt;How can I run blender from command line or a python script without opening a GUI?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blender.stackexchange.com/questions/56011/how-to-use-pip-with-blenders-bundled-python"&gt;How to use PIP with Blender's bundled Python?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="Blender"></category><category term="pip"></category></entry><entry><title>Installing legacy PyTorch for Windows</title><link href="http://tonyromarock.github.io/legacy-pytorch-750m.html" rel="alternate"></link><published>2018-09-12T14:20:00+02:00</published><updated>2018-09-12T14:20:00+02:00</updated><author><name>Peter Mortimer</name></author><id>tag:tonyromarock.github.io,2018-09-12:/legacy-pytorch-750m.html</id><summary type="html">&lt;p&gt;Some helpful notes when installing Pytorch 0.3.0 on a Windows PC with a GeForce GT 750M.&lt;/p&gt;</summary><content type="html">&lt;p&gt;It can be useful to have a working version of PyTorch installed on your outdated local Windows machine to be able to run the prediction of pre-trained models written in PyTorch. I encountered a few roadblocks during my installation, where I really wished for more information on the web somewhere. Therefore, here are some notes I have made while installing PyTorch on my outdated laptop (Acer Aspire from 2013).&lt;/p&gt;
&lt;p&gt;You cannot run the most recent version of PyTorch (0.4.0 at the time of writing) with GPU support on an older machine with an outdated graphics card. In my case my Acer Aspire from 2013 has a NVIDIA GeForce GT 750M. The GeForce GT 750M has a CUDA compute capability of 3.0. You can look up the compute capability of all CUDA GPUs on &lt;a href="https://developer.nvidia.com/cuda-gpus"&gt;this official NVIDIA page&lt;/a&gt;.
The most recent version of PyTorch that still supports a GPU with a compute capability of 3.0 is PyTorch 0.3.0.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/peterjc123/pytorch-scripts"&gt;This GitHub repository&lt;/a&gt; from user &lt;strong&gt;peterjc123&lt;/strong&gt; is very helpful when trying to install PyTorch on Windows. The windows-specific PyTorch packages are available as conda packages here. 
The README of this repository also refers to a &lt;a href="https://drive.google.com/drive/folders/0B-X0-FlSGfCYdTNldW02UGl4MXM"&gt;Google Drive&lt;/a&gt; that includes conda packages for legacy versions of PyTorch for Windows. Here you have to check for the correct conda package. In my case I am running Python 3.6 and CUDA 8.0. I had to download the following compressed package:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pytorch_legacy-0.3.0-py36_0.3.0cu80.tar.bz2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Move the compressed conda package to your working directory. Now you can locally install this conda package in your conda environment with the following command.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conda install --offline pytorch_legacy-0.3.0-py36_0.3.0cu80.tar.bz2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can quickly check if this version of PyTorch correctly detects the CUDA installation in your Python interpreter with the following commands:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch&lt;/span&gt;
&lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cuda&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_available&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If this returns &lt;strong&gt;True&lt;/strong&gt; then you should be ready to run legacy PyTorch on Windows.&lt;/p&gt;</content><category term="legacy PyTorch"></category><category term="Windows"></category><category term="GeForce GT 750M"></category></entry></feed>